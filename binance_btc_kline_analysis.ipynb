{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å¸å®‰BTC Kçº¿æ•°æ®åˆ†æ\n",
    "\n",
    "æœ¬notebookä»å¸å®‰APIæ‹‰å–BTCæœ€è¿‘90å¤©çš„å°æ—¶çº§Kçº¿æ•°æ®ï¼Œç”Ÿæˆæ¯æ—¥Kçº¿å›¾å¹¶ä¸Šä¼ åˆ°S3å­˜å‚¨æ¡¶ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. å®‰è£…å’Œå¯¼å…¥å¿…è¦çš„åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…å¿…è¦çš„åŒ…\n",
    "!pip install requests pandas matplotlib seaborn boto3 python-binance plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.patches import Rectangle\n",
    "import seaborn as sns\n",
    "import boto3\n",
    "from datetime import datetime, timedelta\n",
    "import io\n",
    "import os\n",
    "from binance.client import Client\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®matplotlibä¸­æ–‡å­—ä½“æ”¯æŒ\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. é…ç½®å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é…ç½®å‚æ•°\n",
    "SYMBOL = 'BTCUSDT'\n",
    "DAYS_BACK = 90\n",
    "INTERVAL = '1h'  # 1å°æ—¶Kçº¿\n",
    "\n",
    "# S3é…ç½® - è¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹\n",
    "S3_BUCKET = 'your-s3-bucket-name'  # æ›¿æ¢ä¸ºä½ çš„S3å­˜å‚¨æ¡¶åç§°\n",
    "S3_PREFIX = 'btc-kline-charts/'    # S3ä¸­çš„æ–‡ä»¶å¤¹å‰ç¼€\n",
    "\n",
    "# AWSåŒºåŸŸ\n",
    "AWS_REGION = 'us-east-1'  # æ ¹æ®éœ€è¦ä¿®æ”¹åŒºåŸŸ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ä»å¸å®‰APIè·å–Kçº¿æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binance_klines(symbol, interval, days_back):\n",
    "    \"\"\"\n",
    "    ä»å¸å®‰APIè·å–Kçº¿æ•°æ®\n",
    "    \"\"\"\n",
    "    # è®¡ç®—å¼€å§‹æ—¶é—´\n",
    "    end_time = datetime.now()\n",
    "    start_time = end_time - timedelta(days=days_back)\n",
    "    \n",
    "    # è½¬æ¢ä¸ºæ¯«ç§’æ—¶é—´æˆ³\n",
    "    start_timestamp = int(start_time.timestamp() * 1000)\n",
    "    end_timestamp = int(end_time.timestamp() * 1000)\n",
    "    \n",
    "    # å¸å®‰APIç«¯ç‚¹\n",
    "    url = 'https://api.binance.com/api/v3/klines'\n",
    "    \n",
    "    params = {\n",
    "        'symbol': symbol,\n",
    "        'interval': interval,\n",
    "        'startTime': start_timestamp,\n",
    "        'endTime': end_timestamp,\n",
    "        'limit': 1000  # æ¯æ¬¡æœ€å¤šè·å–1000æ¡æ•°æ®\n",
    "    }\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    while start_timestamp < end_timestamp:\n",
    "        params['startTime'] = start_timestamp\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, params=params)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            if not data:\n",
    "                break\n",
    "                \n",
    "            all_data.extend(data)\n",
    "            \n",
    "            # æ›´æ–°å¼€å§‹æ—¶é—´ä¸ºæœ€åä¸€æ¡æ•°æ®çš„æ—¶é—´+1æ¯«ç§’\n",
    "            start_timestamp = data[-1][6] + 1  # ä½¿ç”¨close time + 1\n",
    "            \n",
    "            print(f\"å·²è·å– {len(all_data)} æ¡Kçº¿æ•°æ®...\")\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"APIè¯·æ±‚é”™è¯¯: {e}\")\n",
    "            break\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "# è·å–Kçº¿æ•°æ®\n",
    "print(f\"æ­£åœ¨è·å– {SYMBOL} æœ€è¿‘ {DAYS_BACK} å¤©çš„ {INTERVAL} Kçº¿æ•°æ®...\")\n",
    "kline_data = get_binance_klines(SYMBOL, INTERVAL, DAYS_BACK)\n",
    "print(f\"æ€»å…±è·å–äº† {len(kline_data)} æ¡Kçº¿æ•°æ®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. æ•°æ®å¤„ç†å’Œæ¸…æ´—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_kline_data(kline_data):\n",
    "    \"\"\"\n",
    "    å¤„ç†Kçº¿æ•°æ®ï¼Œè½¬æ¢ä¸ºDataFrameæ ¼å¼\n",
    "    \"\"\"\n",
    "    columns = [\n",
    "        'open_time', 'open', 'high', 'low', 'close', 'volume',\n",
    "        'close_time', 'quote_asset_volume', 'number_of_trades',\n",
    "        'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'\n",
    "    ]\n",
    "    \n",
    "    df = pd.DataFrame(kline_data, columns=columns)\n",
    "    \n",
    "    # è½¬æ¢æ•°æ®ç±»å‹\n",
    "    numeric_columns = ['open', 'high', 'low', 'close', 'volume', \n",
    "                      'quote_asset_volume', 'number_of_trades',\n",
    "                      'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume']\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # è½¬æ¢æ—¶é—´æˆ³\n",
    "    df['open_time'] = pd.to_datetime(df['open_time'], unit='ms')\n",
    "    df['close_time'] = pd.to_datetime(df['close_time'], unit='ms')\n",
    "    \n",
    "    # æ·»åŠ æ—¥æœŸåˆ—\n",
    "    df['date'] = df['open_time'].dt.date\n",
    "    \n",
    "    # è®¾ç½®ç´¢å¼•\n",
    "    df.set_index('open_time', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# å¤„ç†æ•°æ®\n",
    "df = process_kline_data(kline_data)\n",
    "print(f\"æ•°æ®å¤„ç†å®Œæˆï¼Œæ•°æ®å½¢çŠ¶: {df.shape}\")\n",
    "print(f\"æ•°æ®æ—¶é—´èŒƒå›´: {df.index.min()} åˆ° {df.index.max()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ç”Ÿæˆæ¯æ—¥Kçº¿å›¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_daily_kline_chart(daily_data, date_str):\n",
    "    \"\"\"\n",
    "    åˆ›å»ºå•æ—¥Kçº¿å›¾\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10), \n",
    "                                   gridspec_kw={'height_ratios': [3, 1]})\n",
    "    \n",
    "    # ä¸»å›¾ï¼šKçº¿å›¾\n",
    "    for idx, (timestamp, row) in enumerate(daily_data.iterrows()):\n",
    "        # ç¡®å®šé¢œè‰²ï¼ˆçº¢æ¶¨ç»¿è·Œï¼‰\n",
    "        color = 'red' if row['close'] >= row['open'] else 'green'\n",
    "        \n",
    "        # ç»˜åˆ¶å½±çº¿\n",
    "        ax1.plot([idx, idx], [row['low'], row['high']], color='black', linewidth=1)\n",
    "        \n",
    "        # ç»˜åˆ¶å®ä½“\n",
    "        height = abs(row['close'] - row['open'])\n",
    "        bottom = min(row['open'], row['close'])\n",
    "        \n",
    "        rect = Rectangle((idx-0.3, bottom), 0.6, height, \n",
    "                        facecolor=color, edgecolor='black', alpha=0.8)\n",
    "        ax1.add_patch(rect)\n",
    "    \n",
    "    # è®¾ç½®ä¸»å›¾\n",
    "    ax1.set_title(f'BTC/USDT {date_str} å°æ—¶Kçº¿å›¾', fontsize=16, fontweight='bold')\n",
    "    ax1.set_ylabel('ä»·æ ¼ (USDT)', fontsize=12)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # è®¾ç½®xè½´æ ‡ç­¾\n",
    "    hours = [f\"{i:02d}:00\" for i in range(0, 24, 2)]\n",
    "    ax1.set_xticks(range(0, len(daily_data), 2))\n",
    "    ax1.set_xticklabels(hours, rotation=45)\n",
    "    \n",
    "    # æ·»åŠ ä»·æ ¼ä¿¡æ¯\n",
    "    daily_open = daily_data.iloc[0]['open']\n",
    "    daily_close = daily_data.iloc[-1]['close']\n",
    "    daily_high = daily_data['high'].max()\n",
    "    daily_low = daily_data['low'].min()\n",
    "    daily_volume = daily_data['volume'].sum()\n",
    "    \n",
    "    change = daily_close - daily_open\n",
    "    change_pct = (change / daily_open) * 100\n",
    "    \n",
    "    info_text = f\"å¼€ç›˜: ${daily_open:.2f} | æ”¶ç›˜: ${daily_close:.2f} | æœ€é«˜: ${daily_high:.2f} | æœ€ä½: ${daily_low:.2f}\\n\"\n",
    "    info_text += f\"æ¶¨è·Œ: ${change:.2f} ({change_pct:+.2f}%) | æˆäº¤é‡: {daily_volume:.2f}\"\n",
    "    \n",
    "    ax1.text(0.02, 0.98, info_text, transform=ax1.transAxes, \n",
    "             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "    \n",
    "    # å‰¯å›¾ï¼šæˆäº¤é‡\n",
    "    colors = ['red' if row['close'] >= row['open'] else 'green' \n",
    "              for _, row in daily_data.iterrows()]\n",
    "    \n",
    "    ax2.bar(range(len(daily_data)), daily_data['volume'], color=colors, alpha=0.7)\n",
    "    ax2.set_ylabel('æˆäº¤é‡', fontsize=12)\n",
    "    ax2.set_xlabel('æ—¶é—´', fontsize=12)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax2.set_xticks(range(0, len(daily_data), 2))\n",
    "    ax2.set_xticklabels(hours, rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# æŒ‰æ—¥æœŸåˆ†ç»„æ•°æ®\n",
    "daily_groups = df.groupby('date')\n",
    "print(f\"æ€»å…±æœ‰ {len(daily_groups)} å¤©çš„æ•°æ®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. åˆå§‹åŒ–S3å®¢æˆ·ç«¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆå§‹åŒ–S3å®¢æˆ·ç«¯\n",
    "try:\n",
    "    s3_client = boto3.client('s3', region_name=AWS_REGION)\n",
    "    print(\"S3å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ\")\n",
    "    \n",
    "    # æ£€æŸ¥å­˜å‚¨æ¡¶æ˜¯å¦å­˜åœ¨\n",
    "    try:\n",
    "        s3_client.head_bucket(Bucket=S3_BUCKET)\n",
    "        print(f\"S3å­˜å‚¨æ¡¶ '{S3_BUCKET}' å¯è®¿é—®\")\n",
    "    except:\n",
    "        print(f\"è­¦å‘Š: æ— æ³•è®¿é—®S3å­˜å‚¨æ¡¶ '{S3_BUCKET}'ï¼Œè¯·æ£€æŸ¥å­˜å‚¨æ¡¶åç§°å’Œæƒé™\")\n",
    "        print(\"å°†åœ¨æœ¬åœ°ä¿å­˜å›¾ç‰‡æ–‡ä»¶\")\n",
    "        S3_BUCKET = None\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"S3å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}\")\n",
    "    print(\"å°†åœ¨æœ¬åœ°ä¿å­˜å›¾ç‰‡æ–‡ä»¶\")\n",
    "    S3_BUCKET = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ç”Ÿæˆå›¾è¡¨å¹¶ä¸Šä¼ åˆ°S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_s3(fig, filename, s3_client, bucket, prefix):\n",
    "    \"\"\"\n",
    "    å°†matplotlibå›¾è¡¨ä¸Šä¼ åˆ°S3\n",
    "    \"\"\"\n",
    "    if not bucket:\n",
    "        # æœ¬åœ°ä¿å­˜\n",
    "        local_dir = 'btc_charts'\n",
    "        os.makedirs(local_dir, exist_ok=True)\n",
    "        local_path = os.path.join(local_dir, filename)\n",
    "        fig.savefig(local_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"å›¾è¡¨å·²ä¿å­˜åˆ°æœ¬åœ°: {local_path}\")\n",
    "        return local_path\n",
    "    \n",
    "    try:\n",
    "        # å°†å›¾è¡¨ä¿å­˜åˆ°å†…å­˜ä¸­çš„å­—èŠ‚æµ\n",
    "        img_buffer = io.BytesIO()\n",
    "        fig.savefig(img_buffer, format='png', dpi=300, bbox_inches='tight')\n",
    "        img_buffer.seek(0)\n",
    "        \n",
    "        # ä¸Šä¼ åˆ°S3\n",
    "        s3_key = f\"{prefix}{filename}\"\n",
    "        s3_client.upload_fileobj(\n",
    "            img_buffer, \n",
    "            bucket, \n",
    "            s3_key,\n",
    "            ExtraArgs={'ContentType': 'image/png'}\n",
    "        )\n",
    "        \n",
    "        s3_url = f\"https://{bucket}.s3.{AWS_REGION}.amazonaws.com/{s3_key}\"\n",
    "        print(f\"å›¾è¡¨å·²ä¸Šä¼ åˆ°S3: {s3_url}\")\n",
    "        return s3_url\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ä¸Šä¼ åˆ°S3å¤±è´¥: {e}\")\n",
    "        # å¤‡ç”¨ï¼šä¿å­˜åˆ°æœ¬åœ°\n",
    "        local_dir = 'btc_charts'\n",
    "        os.makedirs(local_dir, exist_ok=True)\n",
    "        local_path = os.path.join(local_dir, filename)\n",
    "        fig.savefig(local_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"å›¾è¡¨å·²ä¿å­˜åˆ°æœ¬åœ°: {local_path}\")\n",
    "        return local_path\n",
    "\n",
    "# ç”Ÿæˆæ‰€æœ‰æ—¥æœŸçš„Kçº¿å›¾\n",
    "uploaded_files = []\n",
    "total_days = len(daily_groups)\n",
    "\n",
    "print(f\"å¼€å§‹ç”Ÿæˆ {total_days} å¤©çš„Kçº¿å›¾...\")\n",
    "\n",
    "for i, (date, daily_data) in enumerate(daily_groups, 1):\n",
    "    date_str = date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®ï¼ˆè‡³å°‘æœ‰å‡ ä¸ªå°æ—¶çš„æ•°æ®ï¼‰\n",
    "    if len(daily_data) < 5:\n",
    "        print(f\"è·³è¿‡ {date_str}ï¼šæ•°æ®ä¸è¶³ ({len(daily_data)} æ¡è®°å½•)\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"æ­£åœ¨å¤„ç† {date_str} ({i}/{total_days})...\")\n",
    "    \n",
    "    try:\n",
    "        # åˆ›å»ºKçº¿å›¾\n",
    "        fig = create_daily_kline_chart(daily_data, date_str)\n",
    "        \n",
    "        # ç”Ÿæˆæ–‡ä»¶å\n",
    "        filename = f\"BTC_USDT_1h_{date_str}.png\"\n",
    "        \n",
    "        # ä¸Šä¼ åˆ°S3æˆ–ä¿å­˜åˆ°æœ¬åœ°\n",
    "        file_location = upload_to_s3(fig, filename, s3_client, S3_BUCKET, S3_PREFIX)\n",
    "        uploaded_files.append({\n",
    "            'date': date_str,\n",
    "            'filename': filename,\n",
    "            'location': file_location\n",
    "        })\n",
    "        \n",
    "        # å…³é—­å›¾è¡¨ä»¥é‡Šæ”¾å†…å­˜\n",
    "        plt.close(fig)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"å¤„ç† {date_str} æ—¶å‡ºé”™: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nå®Œæˆï¼æ€»å…±ç”Ÿæˆäº† {len(uploaded_files)} ä¸ªKçº¿å›¾\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºæ±‡æ€»æŠ¥å‘Š\n",
    "summary_df = pd.DataFrame(uploaded_files)\n",
    "\n",
    "if not summary_df.empty:\n",
    "    print(\"\\n=== ç”Ÿæˆçš„Kçº¿å›¾æ±‡æ€» ===\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    # ä¿å­˜æ±‡æ€»æŠ¥å‘Š\n",
    "    summary_filename = f\"btc_kline_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "    \n",
    "    if S3_BUCKET:\n",
    "        # ä¸Šä¼ æ±‡æ€»æŠ¥å‘Šåˆ°S3\n",
    "        csv_buffer = io.StringIO()\n",
    "        summary_df.to_csv(csv_buffer, index=False)\n",
    "        csv_buffer.seek(0)\n",
    "        \n",
    "        try:\n",
    "            s3_client.upload_fileobj(\n",
    "                io.BytesIO(csv_buffer.getvalue().encode()),\n",
    "                S3_BUCKET,\n",
    "                f\"{S3_PREFIX}{summary_filename}\",\n",
    "                ExtraArgs={'ContentType': 'text/csv'}\n",
    "            )\n",
    "            print(f\"\\næ±‡æ€»æŠ¥å‘Šå·²ä¸Šä¼ åˆ°S3: {S3_PREFIX}{summary_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"ä¸Šä¼ æ±‡æ€»æŠ¥å‘Šå¤±è´¥: {e}\")\n",
    "            summary_df.to_csv(summary_filename, index=False)\n",
    "            print(f\"æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜åˆ°æœ¬åœ°: {summary_filename}\")\n",
    "    else:\n",
    "        summary_df.to_csv(summary_filename, index=False)\n",
    "        print(f\"\\næ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜åˆ°æœ¬åœ°: {summary_filename}\")\n",
    "else:\n",
    "    print(\"\\næ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•Kçº¿å›¾\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. æ•°æ®ç»Ÿè®¡åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆæ•°æ®ç»Ÿè®¡\n",
    "print(\"\\n=== BTCä»·æ ¼ç»Ÿè®¡åˆ†æ ===\")\n",
    "print(f\"æ•°æ®æ—¶é—´èŒƒå›´: {df.index.min().strftime('%Y-%m-%d %H:%M')} åˆ° {df.index.max().strftime('%Y-%m-%d %H:%M')}\")\n",
    "print(f\"æ€»æ•°æ®ç‚¹æ•°: {len(df)}\")\n",
    "print(f\"\\nä»·æ ¼ç»Ÿè®¡:\")\n",
    "print(f\"  æœ€é«˜ä»·: ${df['high'].max():.2f}\")\n",
    "print(f\"  æœ€ä½ä»·: ${df['low'].min():.2f}\")\n",
    "print(f\"  å¹³å‡ä»·: ${df['close'].mean():.2f}\")\n",
    "print(f\"  æœŸé—´æ¶¨è·Œ: ${df['close'].iloc[-1] - df['open'].iloc[0]:.2f}\")\n",
    "print(f\"  æœŸé—´æ¶¨è·Œå¹…: {((df['close'].iloc[-1] / df['open'].iloc[0]) - 1) * 100:.2f}%\")\n",
    "print(f\"\\næˆäº¤é‡ç»Ÿè®¡:\")\n",
    "print(f\"  æ€»æˆäº¤é‡: {df['volume'].sum():.2f} BTC\")\n",
    "print(f\"  å¹³å‡å°æ—¶æˆäº¤é‡: {df['volume'].mean():.2f} BTC\")\n",
    "print(f\"  æœ€å¤§å°æ—¶æˆäº¤é‡: {df['volume'].max():.2f} BTC\")\n",
    "\n",
    "# è®¡ç®—æ¯æ—¥ç»Ÿè®¡\n",
    "daily_stats = df.groupby('date').agg({\n",
    "    'open': 'first',\n",
    "    'high': 'max',\n",
    "    'low': 'min',\n",
    "    'close': 'last',\n",
    "    'volume': 'sum'\n",
    "})\n",
    "\n",
    "daily_stats['daily_change'] = daily_stats['close'] - daily_stats['open']\n",
    "daily_stats['daily_change_pct'] = (daily_stats['daily_change'] / daily_stats['open']) * 100\n",
    "\n",
    "print(f\"\\næ¯æ—¥ç»Ÿè®¡:\")\n",
    "print(f\"  ä¸Šæ¶¨å¤©æ•°: {(daily_stats['daily_change'] > 0).sum()}\")\n",
    "print(f\"  ä¸‹è·Œå¤©æ•°: {(daily_stats['daily_change'] < 0).sum()}\")\n",
    "print(f\"  æœ€å¤§å•æ—¥æ¶¨å¹…: {daily_stats['daily_change_pct'].max():.2f}%\")\n",
    "print(f\"  æœ€å¤§å•æ—¥è·Œå¹…: {daily_stats['daily_change_pct'].min():.2f}%\")\n",
    "print(f\"  å¹³å‡æ—¥æ³¢åŠ¨ç‡: {daily_stats['daily_change_pct'].abs().mean():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. å®Œæˆæç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ‰ BTC Kçº¿æ•°æ®åˆ†æå®Œæˆï¼\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if S3_BUCKET:\n",
    "    print(f\"ğŸ“Š æ‰€æœ‰Kçº¿å›¾å·²ä¸Šä¼ åˆ°S3å­˜å‚¨æ¡¶: {S3_BUCKET}\")\n",
    "    print(f\"ğŸ“ S3è·¯å¾„å‰ç¼€: {S3_PREFIX}\")\n",
    "else:\n",
    "    print(f\"ğŸ“Š æ‰€æœ‰Kçº¿å›¾å·²ä¿å­˜åˆ°æœ¬åœ°ç›®å½•: btc_charts/\")\n",
    "\n",
    "print(f\"ğŸ“ˆ æ€»å…±ç”Ÿæˆäº† {len(uploaded_files)} ä¸ªæ¯æ—¥Kçº¿å›¾\")\n",
    "print(f\"ğŸ“‹ æ±‡æ€»æŠ¥å‘Šæ–‡ä»¶: {summary_filename if 'summary_filename' in locals() else 'N/A'}\")\n",
    "print(f\"â° å¤„ç†å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(\"\\nå¦‚éœ€é‡æ–°è¿è¡Œæˆ–ä¿®æ”¹å‚æ•°ï¼Œè¯·ä¿®æ”¹ç¬¬2èŠ‚çš„é…ç½®å‚æ•°åé‡æ–°æ‰§è¡Œç›¸å…³å•å…ƒæ ¼ã€‚\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
